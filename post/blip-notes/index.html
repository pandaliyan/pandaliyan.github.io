<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Wenyan Li" />

  
  
  
    
  
  <meta name="description" content="Notes on BLIP models" />

  
  <link rel="alternate" hreflang="en-us" href="https://wenyanli.org/post/blip-notes/" />

  
  
  
    <meta name="theme-color" content="#bbdefb" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.2215a8106e8600c1296dee0a44c6a5ab.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://wenyanli.org/post/blip-notes/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Wenyan Li" />
  <meta property="og:url" content="https://wenyanli.org/post/blip-notes/" />
  <meta property="og:title" content="BLIP models | Wenyan Li" />
  <meta property="og:description" content="Notes on BLIP models" /><meta property="og:image" content="https://wenyanli.org/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://wenyanli.org/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2023-11-06T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2023-11-06T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://wenyanli.org/post/blip-notes/"
  },
  "headline": "BLIP models",
  
  "datePublished": "2023-11-06T00:00:00Z",
  "dateModified": "2023-11-06T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Wenyan Li"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Wenyan Li",
    "logo": {
      "@type": "ImageObject",
      "url": "https://wenyanli.org/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Notes on BLIP models"
}
</script>

  

  

  

  





  <title>BLIP models | Wenyan Li</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper  dark " data-wc-page-id="ff88e1e50c9008bb5ca648cd6fffdb36" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.7139d4fb8f74c01b97e65e19c846e5cc.js"></script>

  




  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Wenyan Li</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Wenyan Li</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/uploads/wenyanli_cv.pdf"><span>CV</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>BLIP models</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Wenyan Li</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Nov 6, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/reading/">reading</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <h1 id="blips">BLIPs</h1>
<table>
<thead>
<tr>
<th></th>
<th>BLIP</th>
<th>BLIP2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Image Encoder</td>
<td>updated</td>
<td>frozen</td>
</tr>
<tr>
<td>Text encoder/decoder</td>
<td>updated</td>
<td>frozen</td>
</tr>
<tr>
<td>Transformer</td>
<td>updated （BERT）</td>
<td>query transformer (Q-Former)， including query embeddings （additional）</td>
</tr>
<tr>
<td>pre-training</td>
<td>pretraining with CapFilt</td>
<td>2 stage pretraining with CapFilt</td>
</tr>
</tbody>
</table>
<h2 id="blip">BLIP</h2>
<h3 id="main-method">Main method:</h3>
<ul>
<li><code>CapFilt</code>: generate synthetic captions and filter to get <code>(img,txt)</code> pairs</li>
<li><code>Multimodal mixture of Encoder-Decoder (MED)</code></li>
</ul>
<h3 id="med">MED</h3>
<p><strong>Model structure:</strong></p>
<ul>
<li>
<p>Image encoder</p>
</li>
<li>
<p>Text encoder — BERT(Bi SelfAttn, FF)</p>
<p>这一大块的模型变种共享除了self attention以外的参数</p>
<ul>
<li>
<ul>
<li>additional cross attention ⇒ Image-grounded Text Encoder
<ul>
<li>injects visual information with <code>[Encode]</code> token</li>
</ul>
</li>
</ul>
</li>
<li>
<ul>
<li>selfAttn + Casual SelfAttn⇒ Image-grounded Text Decoder</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Three vision-language objectives</strong>:</p>
<p>分别与上面text相关模块变种负责的功能对应</p>
<ul>
<li>image text contrastive learning (ITC)</li>
<li>image-text matching (ITM)</li>
<li>image conditioned language modeling (ITG/LM)</li>
</ul>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_17.59.49.png" alt="Screenshot 2023-02-08 at 17.59.49.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h3 id="capfilt">CapFilt</h3>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_18.10.25.png" alt="Screenshot 2023-02-08 at 18.10.25.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>用COCO训练了一个captioning模型用来生成synthetic captions. Image-grounded text encoder用来过滤所生成的captions。</p>
<h3 id="experiments">Experiments</h3>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_18.21.41.png" alt="Screenshot 2023-02-08 at 18.21.41.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<ul>
<li>CapFilt 机制能够比较好地改善模型效果，对比网络抓取的caption，生成的caption效果更好。</li>
</ul>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_18.15.36.png" alt="Screenshot 2023-02-08 at 18.15.36.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>下游任务在VQA, retrieval, NLVR2, visual dialog以及captioning都做了evaluation。效果均超过baseline， 使用CAPFILT后效果在BLIP base上进一步提升。</p>
<hr>
<h1 id="blip2">BLIP2</h1>
<h3 id="main-method-1">Main method:</h3>
<ul>
<li>Image encoder 和 LLM 都是frozen的，只有<code>querying  transformer</code> 参数更新。
<ul>
<li><code>Q-former</code>通过两个阶段的预训练起到一个两个模态间的桥梁作用，且轻量</li>
</ul>
</li>
<li><code>Q-former</code> Training involves two stages:
<ul>
<li>
<ol>
<li>bootstrapping image encoder</li>
</ol>
</li>
<li>
<ol start="2">
<li>bootstrapping LLM</li>
</ol>
</li>
</ul>
</li>
<li>Data: 129M images (COCO, VG, CC12M, SBU, LAION400M) + BLIP caption + CapFilt</li>
<li>Submodules:
<ul>
<li>Image encoder:</li>
<li>LLM: decoder-only OPT; encoder-decoder instruction-trained FlanT5</li>
</ul>
</li>
</ul>
<h3 id="main-contribution">Main contribution:</h3>
<p>提出更轻量的VL模型，outperform Flamingo but 54x lighter.</p>
<h3 id="problemschallenges-in-previous-models">Problems/challenges in previous models:</h3>
<ul>
<li><code>image-to-text generation loss</code> are <strong>not sufficient</strong> to bridge modality gap from pretrained frozen models.</li>
<li><strong><strong><strong><strong>how to do better vision-language alignment? 如何实现多模态预训练模型之间的alignment？</strong></strong></strong></strong></li>
</ul>
<h3 id="heading"></h3>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_14.26.58.png" alt="Screenshot 2023-02-08 at 14.26.58.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h3 id="q-former"><strong>Q-Former</strong>:</h3>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_14.53.33.png" alt="Screenshot 2023-02-08 at 14.53.33.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p><strong>Model structure</strong></p>
<ul>
<li>
<p>two transformers:  这两个transformer同时也对应两个阶段的预训练</p>
<ul>
<li>image transformer: 从image encoder提取visual feature
<ul>
<li>bottle neck for feature extraction (比直接使用frozen image encoder更轻量）</li>
</ul>
</li>
<li>text transformer：function as both a text encoder and a text decoder (既可以当encoder用也可以当decoder用）</li>
</ul>
</li>
<li>
<p>inputs: (image, text)</p>
</li>
<li>
<p>loss:</p>
<ul>
<li>
<ol>
<li>image-text matching  （ITM）— bidirectional</li>
</ol>
</li>
<li>
<ol start="2">
<li>image-text contrastive learning （ITC）— unimodal masking</li>
</ol>
</li>
<li>
<ol start="3">
<li>image-grounded text generation （ITG）— causal self-attention masking</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_15.06.51.png" alt="Screenshot 2023-02-08 at 15.06.51.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
</li>
</ul>
</li>
<li>
<p>实现细节</p>
<ul>
<li>自注意力层共享参数;</li>
<li>通过query embeddings和共享的自注意力层实现针对不同人物不同方式的图文交互
<ul>
<li>query embedding (32x768)</li>
</ul>
</li>
<li>weights initialised from $BERT_{base}$ （188M #parameters）</li>
</ul>
</li>
</ul>
<p><strong>Learning stages</strong></p>
<ul>
<li>
<p>representation learning： 学习图像文本的相关性 alignment  (frozen image encoder)</p>
<blockquote>
<p>we perform vision-language representation learning which enforces the Q-Former to learn visual representation most relevant to the text.</p>
</blockquote>
</li>
<li>
<p>generative learning： 有点像prompt- tuning，让学习到的图像feature适配LLM (frozen LLM)</p>
<p>这个适配直接通过FC层完成。LLM 的输入= <code>concat (FC(visual feature);text_embed)</code></p>
<blockquote>
<p>we perform vision-to-language generative learning by connecting the output of the Q-Former to a frozen LLM, and trains the Q-Former such that its output visual representation can be interpreted by the LLM.</p>
</blockquote>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_15.12.25.png" alt="Screenshot 2023-02-08 at 15.12.25.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
</li>
</ul>
<p><strong>Experiments</strong></p>
<p>zero-shot VQA实验效果相当惊艳，秒杀一系列超大模型。Text-encoder部分使用FlanT5效果显著。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_16.17.30.png" alt="Screenshot 2023-02-08 at 16.17.30.png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>I<strong>mage captioning</strong></p>
<p>NoCaps zeroshot performance显著超越baseline，但是在COCO上finetune后的结果并没有提高。这里我认为是因为Image encoder和LLM都是超大模型，如果finetune image encoder反而会减弱它的能力（与之前的Frozen道理相同）。但是不太理解为什么这里作者要去对image encoder进行finetune，也没有给出只finetune Q-Former的对比实验。按道理来说还是一样去finetune Q-Former应该就能得到比较好的效果了。或者直接给出zero-shot结果。</p>
<p><strong>Image-text retrieval</strong></p>
<p>retrieval 的实验在BLIP的效果就已经比较饱和了。这里BLIP2在Flickr30k和COCO上都有进一步提升。同样这里BLIP2也是finetune Q-Former 和 image encoder。</p>
<p><strong>Ablation</strong></p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="BLIPs%20a55ad040f589466db86136a738c9cfa2/Screenshot_2023-02-08_at_16.25.15.png" alt="两阶段预训练效果显著，如果去掉第一部分的预训练，下游任务效果会显著下降。" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>两阶段预训练效果显著，如果去掉第一部分的预训练，下游任务效果会显著下降。</p>
<p><strong><strong><strong><strong>Limitation</strong></strong></strong></strong></p>
<ul>
<li>“lack of in-context learning”</li>
<li>“unsatisfactory results due to various reasons including inaccurate knowledge from the LLM, activating the incorrect reasoning path, or not having up-to-date information about new image content”</li>
</ul>

    </div>

    




<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/reading-notes/">reading-notes</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://wenyanli.org/post/blip-notes/&amp;text=BLIP%20models" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://wenyanli.org/post/blip-notes/&amp;t=BLIP%20models" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=BLIP%20models&amp;body=https://wenyanli.org/post/blip-notes/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://wenyanli.org/post/blip-notes/&amp;title=BLIP%20models" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://wenyanli.org/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu84b2a8e4064ccbf3febb8d9666a5885c_139960_270x270_fill_q75_lanczos_center.jpg" alt="Wenyan Li"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://wenyanli.org/">Wenyan Li</a></h5>
      
      <p class="card-text">My research interests include NLP, machine learning and speech recognition.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/Wenyan62" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=JvcZHCsAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="fas fa-graduation-cap"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/lyan62" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/wenyanli/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  

  
  






  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.92d2024afaa4dce0cad42ba360879ce9.js"></script>

    
    
    
      

      
      

      

      

    

    
    
    

    
    

    
    
    

    
    

    
    
    
    

    
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js" type="module"></script>
    
    
    
    
    
    
    
    
    <script src="/en/js/wowchemy.min.b3b95b2ec614292e1913846b81375a58.js"></script>

    
    
    
    
    
    
      
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>






</body>
</html>
