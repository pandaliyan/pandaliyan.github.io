---
title: "An Attentive Recurrent Model for Incremental Prediction of Sentence-final Verbs"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here 
# and it will be replaced with their full name and linked to their profile.
authors:
- "*Wenyan Li*"
- Alvin Grissom II
- Jordan Boyd-Graber


# Author notes (optional)
author_notes:
- ""
- ""

date: "2020-07-01T00:00:00Z"
doi: "10.18653/v1/2020.findings-emnlp.12"

# Schedule page publish date (NOT publication's date).
publishDate: "2020"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: "In *Findings of the Association for Computational Linguistics: EMNLP 2020*"
publication_short: "In *EMNLP findings 2020*"

abstract: "Verb prediction is important for understanding human processing of verb-final languages, 
with practical applications to real-time simultaneous interpretation from verb-final 
to verb-medial languages. While previous approaches use classical statistical models, 
we introduce an attention-based neural model to incrementally predict final verbs on 
incomplete sentences in Japanese and German SOV sentences. 
To offer flexibility to the model, we further incorporate synonym awareness. 
Our approach both better predicts the final verbs in Japanese and German 
and provides more interpretable explanations of why those verbs are selected."

# Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags: [papers]

# Display this page in the Featured widget?
featured: true

math: true

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: /publication/emnlp2020/2020.findings-emnlp.12.pdf
# url_code: ''
# url_dataset: ''
# url_poster: ''
# url_project: ''
# url_slides: ''
# url_source: ''
# url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
# - example

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""

---

## Main idea
"Yu M. et al. (2016), phenotype is translated from genotype based on gene ontology, and predicted interaction 
scores may be influenced by errors in gene annotations or relationship between terms. 
As deep learning being effective in identifying complex patterns from feature-rich datasets, 
especially as recurrent neural networks(RNNs) such as long short term memory(LSTM) and gated recurrent unit(GRU) 
are capable of dealing with long-distance sequential data, predicting genetic interactions directly from DNA or 
amino-acid sequences using deep learning techniques would help us gain insights into underlying complex phenotypes."


# {{% callout note %}}
# Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
# {{% /callout %}}

# {{% callout note %}}
# Create your slides in Markdown - click the *Slides* button to check out the example.
# {{% /callout %}}

# Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
