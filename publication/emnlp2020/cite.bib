@inproceedings{li-etal-2020-attentive,
    title = "An Attentive Recurrent Model for Incremental Prediction of Sentence-final Verbs",
    author = "Li, Wenyan  and
      Grissom II, Alvin  and
      Boyd-Graber, Jordan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.12",
    doi = "10.18653/v1/2020.findings-emnlp.12",
    pages = "126--136",
    abstract = "Verb prediction is important for understanding human processing of verb-final languages, with practical applications to real-time simultaneous interpretation from verb-final to verb-medial languages. While previous approaches use classical statistical models, we introduce an attention-based neural model to incrementally predict final verbs on incomplete sentences in Japanese and German SOV sentences. To offer flexibility to the model, we further incorporate synonym awareness. Our approach both better predicts the final verbs in Japanese and German and provides more interpretable explanations of why those verbs are selected.",
}
